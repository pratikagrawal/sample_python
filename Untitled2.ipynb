{
 "metadata": {
  "name": "",
  "signature": "sha256:c8c8ca51dbcc847a383a9a9ec5479cc13aef9e78f1936b5ec63a5dc7059d9981"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "<pyspark.context.SparkContext at 0x103dd8e10>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "spark_home = os.environ.get('SPARK_HOME', None)\n",
      "text_file = sc.textFile(spark_home + \"/README.md\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_counts = text_file \\\n",
      "    .flatMap(lambda line: line.split()) \\\n",
      "    .map(lambda word: (word, 1)) \\\n",
      "    .reduceByKey(lambda a, b: a + b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_counts.collect()\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "[(u'all', 1),\n",
        " (u'when', 1),\n",
        " (u'\"local\"', 1),\n",
        " (u'including', 3),\n",
        " (u'computation', 1),\n",
        " (u'Spark](#building-spark).', 1),\n",
        " (u'using:', 1),\n",
        " (u'guidance', 3),\n",
        " (u'Scala,', 1),\n",
        " (u'environment', 1),\n",
        " (u'only', 1),\n",
        " (u'rich', 1),\n",
        " (u'Apache', 1),\n",
        " (u'sc.parallelize(range(1000)).count()', 1),\n",
        " (u'Building', 1),\n",
        " (u'guide,', 1),\n",
        " (u'return', 2),\n",
        " (u'Please', 3),\n",
        " (u'Try', 1),\n",
        " (u'not', 1),\n",
        " (u'Spark', 14),\n",
        " (u'scala>', 1),\n",
        " (u'Note', 1),\n",
        " (u'cluster.', 1),\n",
        " (u'./bin/pyspark', 1),\n",
        " (u'have', 1),\n",
        " (u'params', 1),\n",
        " (u'through', 1),\n",
        " (u'GraphX', 1),\n",
        " (u'[run', 1),\n",
        " (u'abbreviated', 1),\n",
        " (u'[project', 2),\n",
        " (u'##', 8),\n",
        " (u'library', 1),\n",
        " (u'see', 1),\n",
        " (u'[Apache', 1),\n",
        " (u'will', 1),\n",
        " (u'#', 1),\n",
        " (u'processing,', 2),\n",
        " (u'for', 11),\n",
        " (u'[building', 1),\n",
        " (u'provides', 1),\n",
        " (u'print', 1),\n",
        " (u'supports', 2),\n",
        " (u'built,', 1),\n",
        " (u'[params]`.', 1),\n",
        " (u'available', 1),\n",
        " (u'run', 7),\n",
        " (u'This', 2),\n",
        " (u'Hadoop,', 2),\n",
        " (u'Tests', 1),\n",
        " (u'example:', 1),\n",
        " (u'-DskipTests', 1),\n",
        " (u'Maven](http://maven.apache.org/).', 1),\n",
        " (u'programming', 1),\n",
        " (u'running', 1),\n",
        " (u'against', 1),\n",
        " (u'site,', 1),\n",
        " (u'comes', 1),\n",
        " (u'package.', 1),\n",
        " (u'and', 10),\n",
        " (u'package.)', 1),\n",
        " (u'prefer', 1),\n",
        " (u'documentation,', 1),\n",
        " (u'submit', 1),\n",
        " (u'tools', 1),\n",
        " (u'use', 3),\n",
        " (u'from', 1),\n",
        " (u'For', 2),\n",
        " (u'fast', 1),\n",
        " (u'systems.', 1),\n",
        " (u'Version\"](http://spark.apache.org/docs/latest/building-with-maven.html#specifying-the-hadoop-version)',\n",
        "  1),\n",
        " (u'<http://spark.apache.org/>', 1),\n",
        " (u'Hadoop-supported', 1),\n",
        " (u'way', 1),\n",
        " (u'README', 1),\n",
        " (u'MASTER', 1),\n",
        " (u'engine', 1),\n",
        " (u'building', 3),\n",
        " (u'usage', 1),\n",
        " (u'Distributions\"](http://spark.apache.org/docs/latest/hadoop-third-party-distributions.html)',\n",
        "  1),\n",
        " (u'instance:', 1),\n",
        " (u'with', 4),\n",
        " (u'protocols', 1),\n",
        " (u'And', 1),\n",
        " (u'this', 1),\n",
        " (u'setup', 1),\n",
        " (u'shell:', 2),\n",
        " (u'project', 1),\n",
        " (u'See', 1),\n",
        " (u'following', 2),\n",
        " (u'distribution', 1),\n",
        " (u'detailed', 2),\n",
        " (u'file', 1),\n",
        " (u'stream', 1),\n",
        " (u'is', 6),\n",
        " (u'higher-level', 1),\n",
        " (u'tests', 1),\n",
        " (u'1000:', 2),\n",
        " (u'sample', 1),\n",
        " (u'[\"Specifying', 1),\n",
        " (u'Alternatively,', 1),\n",
        " (u'./bin/run-example', 2),\n",
        " (u'need', 1),\n",
        " (u'You', 3),\n",
        " (u'instructions.', 1),\n",
        " (u'different', 1),\n",
        " (u'programs,', 1),\n",
        " (u'storage', 1),\n",
        " (u'same', 1),\n",
        " (u'machine', 1),\n",
        " (u'Running', 1),\n",
        " (u'which', 2),\n",
        " (u'you', 4),\n",
        " (u'A', 1),\n",
        " (u'About', 1),\n",
        " (u'sc.parallelize(1', 1),\n",
        " (u'locally.', 1),\n",
        " (u'Hive', 2),\n",
        " (u'optimized', 1),\n",
        " (u'uses', 1),\n",
        " (u'variable', 1),\n",
        " (u'The', 1),\n",
        " (u'data', 2),\n",
        " (u'a', 9),\n",
        " (u'Thriftserver', 1),\n",
        " (u'processing.', 1),\n",
        " (u'./bin/spark-shell', 1),\n",
        " (u'Python', 2),\n",
        " (u'mvn', 1),\n",
        " (u'clean', 1),\n",
        " (u'the', 21),\n",
        " (u'requires', 1),\n",
        " (u'talk', 1),\n",
        " (u'help', 1),\n",
        " (u'automated', 1),\n",
        " (u'Hadoop', 4),\n",
        " (u'using', 2),\n",
        " (u'high-level', 1),\n",
        " (u'find', 1),\n",
        " (u'web', 1),\n",
        " (u'Shell', 2),\n",
        " (u'how', 2),\n",
        " (u'graph', 1),\n",
        " (u'run:', 1),\n",
        " (u'should', 2),\n",
        " (u'to', 14),\n",
        " (u'given.', 1),\n",
        " (u'directory.', 1),\n",
        " (u'must', 1),\n",
        " (u'do', 2),\n",
        " (u'Programs', 1),\n",
        " (u'Many', 1),\n",
        " (u'\"yarn-client\"', 1),\n",
        " (u'YARN,', 1),\n",
        " (u'[\"Third', 1),\n",
        " (u'Example', 1),\n",
        " (u'Once', 1),\n",
        " (u'Spark\"](http://spark.apache.org/docs/latest/building-spark.html).', 1),\n",
        " (u'Because', 1),\n",
        " (u'name', 1),\n",
        " (u'Testing', 1),\n",
        " (u'refer', 2),\n",
        " (u'Streaming', 1),\n",
        " (u'SQL', 2),\n",
        " (u'them,', 1),\n",
        " (u'analysis.', 1),\n",
        " (u'application', 1),\n",
        " (u'set', 2),\n",
        " (u'Scala', 2),\n",
        " (u'thread,', 1),\n",
        " (u'examples', 2),\n",
        " (u'changed', 1),\n",
        " (u'runs.', 1),\n",
        " (u'Pi', 1),\n",
        " (u'More', 1),\n",
        " (u'Python,', 2),\n",
        " (u'Versions', 1),\n",
        " (u'its', 1),\n",
        " (u'version', 1),\n",
        " (u'wiki](https://cwiki.apache.org/confluence/display/SPARK).', 1),\n",
        " (u'`./bin/run-example', 1),\n",
        " (u'Configuration', 1),\n",
        " (u'command,', 2),\n",
        " (u'<class>', 1),\n",
        " (u'core', 1),\n",
        " (u'MASTER=spark://host:7077', 1),\n",
        " (u'Documentation', 1),\n",
        " (u'downloaded', 1),\n",
        " (u'distributions.', 1),\n",
        " (u'Spark.', 1),\n",
        " (u'[\"Building', 1),\n",
        " (u'`examples`', 2),\n",
        " (u'on', 6),\n",
        " (u'works', 1),\n",
        " (u'package', 1),\n",
        " (u'of', 5),\n",
        " (u'APIs', 1),\n",
        " (u'pre-built', 1),\n",
        " (u'Big', 1),\n",
        " (u'\"yarn-cluster\"', 1),\n",
        " (u'or', 3),\n",
        " (u'learning,', 1),\n",
        " (u'structured', 1),\n",
        " (u'overview', 1),\n",
        " (u'one', 2),\n",
        " (u'tests](https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark#ContributingtoSpark-AutomatedTesting).',\n",
        "  1),\n",
        " (u'(You', 1),\n",
        " (u'Online', 1),\n",
        " (u'versions', 1),\n",
        " (u'your', 1),\n",
        " (u'threads.', 1),\n",
        " (u'>>>', 1),\n",
        " (u'SparkPi', 2),\n",
        " (u'contains', 1),\n",
        " (u'system', 1),\n",
        " (u'class', 2),\n",
        " (u'start', 1),\n",
        " (u'basic', 1),\n",
        " (u'configure', 1),\n",
        " (u'that', 3),\n",
        " (u'N', 1),\n",
        " (u'guide](http://spark.apache.org/docs/latest/configuration.html)', 1),\n",
        " (u'particular', 3),\n",
        " (u'be', 2),\n",
        " (u'an', 3),\n",
        " (u'easiest', 1),\n",
        " (u'Interactive', 2),\n",
        " (u'cluster', 2),\n",
        " (u'page](http://spark.apache.org/documentation.html)', 1),\n",
        " (u'can', 6),\n",
        " (u'locally', 2),\n",
        " (u'example', 3),\n",
        " (u'are', 1),\n",
        " (u'Data.', 1),\n",
        " (u'mesos://', 1),\n",
        " (u'computing', 1),\n",
        " (u'URL,', 1),\n",
        " (u'in', 5),\n",
        " (u'general', 2),\n",
        " (u'To', 2),\n",
        " (u'at', 2),\n",
        " (u'1000).count()', 1),\n",
        " (u'Party', 1),\n",
        " (u'if', 4),\n",
        " (u'built', 1),\n",
        " (u'no', 1),\n",
        " (u'Java,', 1),\n",
        " (u'\"local[N]\"', 1),\n",
        " (u'MLlib', 1),\n",
        " (u'also', 5),\n",
        " (u'other', 1),\n",
        " (u'build', 3),\n",
        " (u'online', 1),\n",
        " (u'several', 1),\n",
        " (u'distribution.', 1),\n",
        " (u'HDFS', 1),\n",
        " (u'[Configuration', 1),\n",
        " (u'spark://', 1),\n",
        " (u'programs', 2),\n",
        " (u'documentation', 3),\n",
        " (u'It', 2),\n",
        " (u'graphs', 1),\n",
        " (u'./dev/run-tests', 1),\n",
        " (u'first', 1),\n",
        " (u'latest', 1)]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = sc.parallelize([1,2,3])\n",
      "test.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "3"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark import  SparkContext\n",
      "\n",
      "if 'sc' not in globals():\n",
      "    sc = SparkContext('local[4]', 'notebook')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = sc.textFile('../data/hamlet.txt')\n",
      "words.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "[u'', u'1604', u'', u'', u'THE TRAGEDY OF HAMLET, PRINCE OF DENMARK']"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "hamlet = words.flatMap(lambda line: re.split('\\W+', line.lower().strip()))\n",
      "hamlet.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "[u'', u'1604', u'', u'', u'the']"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = hamlet.filter(lambda x: len(x) > 2 )\n",
      "print tmp.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'1604', u'the', u'tragedy', u'hamlet', u'prince']\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = tmp.map(lambda word: (word, 1))\n",
      "tmp.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "[(u'1604', 1), (u'the', 1), (u'tragedy', 1), (u'hamlet', 1), (u'prince', 1)]"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = tmp.reduceByKey(lambda a, b: a + b)\n",
      "tmp.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[(u'pardon', 9),\n",
        " (u'nunnery', 5),\n",
        " (u'lunacies', 1),\n",
        " (u'all', 125),\n",
        " (u'foul', 12)]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = tmp.map(lambda x: (x[1], x[0])).sortByKey(False)\n",
      "tmp.take(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "[(1091, u'the'),\n",
        " (969, u'and'),\n",
        " (558, u'you'),\n",
        " (405, u'that'),\n",
        " (358, u'ham'),\n",
        " (315, u'not'),\n",
        " (304, u'his'),\n",
        " (300, u'this'),\n",
        " (278, u'with'),\n",
        " (274, u'but'),\n",
        " (252, u'for'),\n",
        " (242, u'your'),\n",
        " (226, u'lord'),\n",
        " (219, u'what'),\n",
        " (203, u'king'),\n",
        " (197, u'him'),\n",
        " (183, u'have'),\n",
        " (173, u'will'),\n",
        " (132, u'are'),\n",
        " (125, u'all')]"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = tmp.map(lambda x: (x[1], x[0]))\n",
      "tmp.take(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[(u'the', 1091),\n",
        " (u'and', 969),\n",
        " (u'you', 558),\n",
        " (u'that', 405),\n",
        " (u'ham', 358),\n",
        " (u'not', 315),\n",
        " (u'his', 304),\n",
        " (u'this', 300),\n",
        " (u'with', 278),\n",
        " (u'but', 274),\n",
        " (u'for', 252),\n",
        " (u'your', 242),\n",
        " (u'lord', 226),\n",
        " (u'what', 219),\n",
        " (u'king', 203),\n",
        " (u'him', 197),\n",
        " (u'have', 183),\n",
        " (u'will', 173),\n",
        " (u'are', 132),\n",
        " (u'all', 125)]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import utils\n",
      "reload(utils)\n",
      "\n",
      "def plot(words):\n",
      "    values = map(lambda x: x[1], words)\n",
      "    labels = map(lambda x: x[0], words)\n",
      "    plt.barh(range(len(values)), values, color='grey')\n",
      "    plt.yticks(range(len(values)), labels)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot(tmp.take(15))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD7CAYAAABqvuNzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2Tw48wAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x109062210>"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = sc.textFile('../data/hamlet.txt')\\\n",
      "        .flatMap(lambda line: re.split('\\W+', line.lower().strip()))\\\n",
      "        .filter(lambda x: len(x) > 2 )\\\n",
      "        .map(lambda word: (word, 1))\\\n",
      "        .reduceByKey(lambda a, b: a + b)\\\n",
      "        .map(lambda x: (x[1], x[0])).sortByKey(False)   \n",
      "\n",
      "words.take(15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "[(1091, u'the'),\n",
        " (969, u'and'),\n",
        " (558, u'you'),\n",
        " (405, u'that'),\n",
        " (358, u'ham'),\n",
        " (315, u'not'),\n",
        " (304, u'his'),\n",
        " (300, u'this'),\n",
        " (278, u'with'),\n",
        " (274, u'but'),\n",
        " (252, u'for'),\n",
        " (242, u'your'),\n",
        " (226, u'lord'),\n",
        " (219, u'what'),\n",
        " (203, u'king')]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_convert_column_funs(rdd, terms, remove_no_variance_columns=False):\n",
      "    '''\n",
      "    For each term, Patsy will determine if the term is a categorical value. If it\n",
      "    is then this will return a function for each dummy variable created. If it is\n",
      "    numeric, then convert it to a float.  Only terms that have non-zero variance are kept.\n",
      "    @param rdd: The RDD to operate against\n",
      "    @param terms: The term names to categorize.\n",
      "    @return: Functions that create categorical dummy variables or numeric variables.\n",
      "    '''\n",
      "    # Since iterating over a large RDD is infeasible, for calculating whether a function or not, \n",
      "    sample = get_sample(rdd, terms)\n",
      "    for t in terms:\n",
      "        if any(t not in df for df in sample):\n",
      "            raise Exception(\"Hey %s is not in sample!\"%t)\n",
      "        if guess_categorical(try_convert_float(df[t]) for df in sample):\n",
      "            categories = sorted(rdd.map(at_index(t)).distinct().collect())\n",
      "            print \"%s is categorical:\" % t, categories\n",
      "            is_first = True\n",
      "            for cat in categories:\n",
      "                if is_first:\n",
      "                    is_first = False\n",
      "                else:\n",
      "                    value_name = \"%s[T.%s]\" % (t, str(cat))\n",
      "                    yield is_present(value_name, t, cat)\n",
      "        else:\n",
      "            print \"%s is numeric\"%t\n",
      "            variance = rdd.map(convert(t)).map(lambda tup: tup[1]).variance()\n",
      "            if variance > 0:\n",
      "                yield convert(t)\n",
      "            else:\n",
      "                if not remove_no_variance_columns:\n",
      "                    print \"WARNING: %s has variance of 0\" % t\n",
      "                    yield convert(t)\n",
      "                else:\n",
      "                    print \"WARNING: %s has variance 0, removing\" % t\n",
      "\n",
      "def get_sample(rdd, terms, n=100):\n",
      "    '''\n",
      "    Returns a sample (First n results, n defaults to 100) from an RDD\n",
      "    @param rdd: The RDD to get sample from\n",
      "    @param terms: The list of terms to return in the sample\n",
      "    @return: The sampled result set as a list of dictionaries\n",
      "    '''\n",
      "    return rdd.map(lambda df: dict((k, df[k]) for k in df if k in terms)).take(n)\n",
      "def guess_categorical(arr):\n",
      "    #return patsy.categorical.guess_categorical(arr)\n",
      "    def _is_float(v):\n",
      "        try:\n",
      "            float(try_convert_float(v))\n",
      "            return True\n",
      "        except:\n",
      "            return False\n",
      "    return not all(_is_float(v) for v in arr)\n",
      "\n",
      "def try_convert_float(n):\n",
      "    '''\n",
      "    Attempts to convert the value into a float. Otherwise leave it in the original format\n",
      "    @param n: The value to convert\n",
      "    @return: The converted value if a float, or the original value.\n",
      "    '''\n",
      "    try:\n",
      "        if n in ('false', 'False', '\\\\N') or n is None:\n",
      "            n = False\n",
      "        elif n == 'true' or n == 'True':\n",
      "            n = True\n",
      "        return float(n)\n",
      "    except:\n",
      "        return n\n",
      "    \n",
      "class convert:\n",
      "    '''\n",
      "    Converts the the value into a float\n",
      "    @param term: The term to convert\n",
      "    @param df: The dataframe to work on\n",
      "    @return: A tuple with the term name and a converted value\n",
      "    '''\n",
      "    def __init__(self, term):\n",
      "        self.term = term\n",
      "    def __call__(self, df):\n",
      "        return (self.term, try_convert_float(df.get(self.term)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_convert_column_funs2(rdd, terms, remove_no_variance_columns=False):\n",
      "    '''\n",
      "    For each term, Patsy will determine if the term is a categorical value. If it\n",
      "    is then this will return a function for each dummy variable created. If it is\n",
      "    numeric, then convert it to a float.  Only terms that have non-zero variance are kept.\n",
      "    @param rdd: The RDD to operate against\n",
      "    @param terms: The term names to categorize.\n",
      "    @return: Functions that create categorical dummy variables or numeric variables.\n",
      "    '''\n",
      "\n",
      "    # Since iterating over a large RDD is infeasible, for calculating whether a function or not, \n",
      "    for t in terms:\n",
      "        variance = rdd.map(convert(t)).map(lambda tup: tup[1]).variance()\n",
      "        print variance\n",
      "        #rdd.map(lambda x: x * x).collect()\n",
      "        if variance>0:\n",
      "            print \"Yes\"\n",
      "            yield convert(t)\n",
      "        else:\n",
      "            print \"None\"\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result2=[f for f in get_convert_column_funs2(rdd,['x','y','z'],True)]\n",
      "rdd.map(lambda df: dict(fun(df) for fun in result2)).collect()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "unsupported operand type(s) for -: 'list' and 'list'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-167-b4d34c9f2c37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_convert_column_funs2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-166-55ea2060855a>\u001b[0m in \u001b[0;36mget_convert_column_funs2\u001b[0;34m(rdd, terms, remove_no_variance_columns)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Since iterating over a large RDD is infeasible, for calculating whether a function or not,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'list'"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result3=rdd.subtractByKey(rdd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rdd = sc.parallelize([{'x':1, 'y':0, 'z':1}, {'x':2, 'y':0, 'z':1}, {'x':3, 'y':0, 'z':1}, {'x':4, 'y':0, 'z':1}], 4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rdd.take(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "[{'x': 1, 'y': 0, 'z': 1}, {'x': 2, 'y': 0, 'z': 1}]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines = sc.textFile('/Users/pagrawal/Documents/repos/ml/rate_competitiveness/hotel_profile.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = lines.map(lambda x: x.split(','))\n",
      "data.take(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "[[u'',\n",
        "  u'compet_prof_key',\n",
        "  u'currency_code',\n",
        "  u'input_city_name',\n",
        "  u'disc_code',\n",
        "  u'star_rating_cnt',\n",
        "  u'promotional_flag',\n",
        "  u'breakfast_flag'],\n",
        " [u'0',\n",
        "  u'1818942',\n",
        "  u'EUR',\n",
        "  u'^QL:103660967||',\n",
        "  u'2.0',\n",
        "  u'3.0',\n",
        "  u'yes',\n",
        "  u'no '],\n",
        " [u'1', u'1819006', u'USD', u'^QL:103607393||', u'0.0', u'', u'no ', u'~  ']]"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result=[f for f in get_convert_column_funs(rdd,['x','y','z'],True)]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "x is numeric\n",
        "y is numeric"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "WARNING: y has variance 0, removing\n",
        "z is numeric\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rdd.map(lambda df: dict(fun(df) for fun in result)).collect()[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "{'x': 2.0, 'z': 1.0}"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_convert_column_funs2(rdd,['x','y','z'],True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 93,
       "text": [
        "<generator object get_convert_column_funs2 at 0x10c33bbe0>"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d1=rdd.take(1)[0]\n",
      "d2=d1\n",
      "keys = d1.keys()\n",
      "d3 = {key: d1[key] - d2.get(key, 0) for key in d1.keys()}\n",
      "d3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resultKeys = [x for x in d3.keys() if [d3[x]!=0]]\n",
      "resultKeys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 191,
       "text": [
        "['y', 'x', 'z']"
       ]
      }
     ],
     "prompt_number": 191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d3={'x':1,'y':0,'z':2}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "x, y\n",
      "1, 2\n",
      "(True, 1), (True, 2)\n",
      "1, (True, 2)\n",
      "(True, 1), 2\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def reduce(x, y):\n",
      "    unique = True\n",
      "    first = None\n",
      "    if isinstance(x, tuple):\n",
      "        unique = x[0]\n",
      "        first = x[1]\n",
      "    else:\n",
      "        first = x\n",
      "        \n",
      "    if isinstance(y, tuple):\n",
      "        unique = unique and y[0]\n",
      "        if first is None:\n",
      "            first = y[1]\n",
      "        else:\n",
      "            unique = unique and first == y[1]\n",
      "    else:\n",
      "        if first is None:\n",
      "            first = y\n",
      "        else:\n",
      "            unique = unique and first == y\n",
      "    return unique, first\n",
      "            \n",
      "\n",
      "v = rdd.map(lambda d: d['y'])\n",
      "print v.collect()\n",
      "v.reduce(reduce)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\n",
        "Traceback (most recent call last):\n",
        "  File \"/Users/pagrawal/Documents/repos/ml/spark-1.2.1/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 425, in start\n",
        "    self.socket.connect((self.address, self.port))\n",
        "  File \"/Users/pagrawal/anaconda/lib/python2.7/socket.py\", line 224, in meth\n",
        "    return getattr(self._sock,name)(*args)\n",
        "error: [Errno 61] Connection refused\n"
       ]
      },
      {
       "ename": "Py4JNetworkError",
       "evalue": "An error occurred while trying to connect to the Java server",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-208-0f4edcfe430a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/pagrawal/Documents/repos/ml/spark-1.2.1/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0mall\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0melements\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \"\"\"\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m             \u001b[0mbytesInJava\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collect_iterator_through_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytesInJava\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/pagrawal/Documents/repos/ml/spark-1.2.1/python/pyspark/traceback_utils.pyc\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark_stack_depth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_site\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark_stack_depth\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/pagrawal/Documents/repos/ml/spark-1.2.1/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         return_value = get_return_value(answer, self.gateway_client,\n\u001b[1;32m    538\u001b[0m                 self.target_id, self.name)\n",
        "\u001b[0;32m/Users/pagrawal/Documents/repos/ml/spark-1.2.1/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry)\u001b[0m\n\u001b[1;32m    360\u001b[0m          \u001b[0mthe\u001b[0m \u001b[0mPy4J\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \"\"\"\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/pagrawal/Documents/repos/ml/spark-1.2.1/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/pagrawal/Documents/repos/ml/spark-1.2.1/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         connection = GatewayConnection(self.address, self.port,\n\u001b[1;32m    324\u001b[0m                 self.auto_close, self.gateway_property)\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/pagrawal/Documents/repos/ml/spark-1.2.1/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;34m'server'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server"
       ]
      }
     ],
     "prompt_number": 208
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def reduce(x, y):\n",
      "    unique = [True for i in x]\n",
      "    first = None\n",
      "    print \"x:%s\\ny:%s\"%(x,y)\n",
      "    if isinstance(x, tuple):\n",
      "        unique = x[0]\n",
      "        first = x[1]\n",
      "    else:\n",
      "        first = x\n",
      "        \n",
      "    if isinstance(y, tuple):\n",
      "        unique = [(i and j) for i,j in zip(unique,y[0])] \n",
      "        if first is None:\n",
      "            first = y[1]\n",
      "        else:\n",
      "            unique = [(i and j == k) for i,j,k in zip(unique,first,y[1])]\n",
      "            unique and first == y[1]\n",
      "    else:\n",
      "        if first is None:\n",
      "            first = y\n",
      "        else:\n",
      "            unique = [(i and j == k) for i,j,k in zip(unique,first,y)]\n",
      "    return unique, first\n",
      "            \n",
      "\n",
      "v = rdd.map(lambda d: d.values())\n",
      "#print v.collect()\n",
      "v.reduce(reduce)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "x:([False, True, False], [1, 2, 1])\n",
        "y:([False, True, True], [3, 2, 1])\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 103,
       "text": [
        "([False, True, False], [1, 2, 1])"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rdd = sc.parallelize([{'x':2, 'y':1, 'z':1}, \n",
      "                      {'x':2, 'y':2, 'z':0}, \n",
      "                      {'x':2, 'y':3, 'z':1}, \n",
      "                      {'x':2, 'y':4, 'z':1}], 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cursor = ()rdd.collect"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "[{'x': 1, 'y': 0, 'z': 1},\n",
        " {'x': 2, 'y': 0, 'z': 1},\n",
        " {'x': 3, 'y': 0, 'z': 2},\n",
        " {'x': 4, 'y': 0, 'z': 3}]"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x=[1,2,3,4]\n",
      "y=[True,False,True,False]\n",
      "unique = [True for i in x]\n",
      "unique    \n",
      "unique = [(i and j) for i,j in zip(unique,y)]\n",
      "unique"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 87,
       "text": [
        "[True, False, True, False]"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Latex\n",
      "Latex(r\"\"\"\\begin{eqnarray}\n",
      "\\nabla \\times \\vec{\\mathbf{B}} -\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{E}}}{\\partial t} & = \\frac{4\\pi}{c}\\vec{\\mathbf{j}} \\\\\n",
      "\\nabla \\cdot \\vec{\\mathbf{E}} & = 4 \\pi \\rho \\\\\n",
      "\\nabla \\times \\vec{\\mathbf{E}}\\, +\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{B}}}{\\partial t} & = \\vec{\\mathbf{0}} \\\\\n",
      "\\nabla \\cdot \\vec{\\mathbf{B}} & = 0 \n",
      "\\end{eqnarray}\"\"\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "\\begin{eqnarray}\n",
        "\\nabla \\times \\vec{\\mathbf{B}} -\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{E}}}{\\partial t} & = \\frac{4\\pi}{c}\\vec{\\mathbf{j}} \\\\\n",
        "\\nabla \\cdot \\vec{\\mathbf{E}} & = 4 \\pi \\rho \\\\\n",
        "\\nabla \\times \\vec{\\mathbf{E}}\\, +\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{B}}}{\\partial t} & = \\vec{\\mathbf{0}} \\\\\n",
        "\\nabla \\cdot \\vec{\\mathbf{B}} & = 0 \n",
        "\\end{eqnarray}"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 104,
       "text": [
        "<IPython.core.display.Latex at 0x106c22c50>"
       ]
      }
     ],
     "prompt_number": 104
    }
   ],
   "metadata": {}
  }
 ]
}